{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_train.pickle\", \"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_train.pickle\", \"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "X_train = X_train/255.0  # normalizacija image-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-conv-64-nodes-0-dense-64--nodes-1561692393\n",
      "WARNING:tensorflow:From C:\\Users\\Nuxx\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 17964 samples, validate on 4492 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Nuxx\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "17964/17964 [==============================] - 716s 40ms/sample - loss: 0.6197 - acc: 0.6428 - val_loss: 0.5884 - val_acc: 0.6892\n",
      "Epoch 2/5\n",
      "17964/17964 [==============================] - 698s 39ms/sample - loss: 0.5116 - acc: 0.7501 - val_loss: 0.4918 - val_acc: 0.7645\n",
      "Epoch 3/5\n",
      "17964/17964 [==============================] - 687s 38ms/sample - loss: 0.4675 - acc: 0.7791 - val_loss: 0.4567 - val_acc: 0.7814\n",
      "Epoch 4/5\n",
      "17964/17964 [==============================] - 727s 40ms/sample - loss: 0.4337 - acc: 0.8008 - val_loss: 0.4436 - val_acc: 0.7943\n",
      "Epoch 5/5\n",
      "17964/17964 [==============================] - 699s 39ms/sample - loss: 0.4074 - acc: 0.8186 - val_loss: 0.4437 - val_acc: 0.7903\n",
      "3-conv-64-nodes-0-dense-64--nodes-1561695923\n",
      "Train on 17964 samples, validate on 4492 samples\n",
      "Epoch 1/5\n",
      "17964/17964 [==============================] - 764s 43ms/sample - loss: 0.6135 - acc: 0.6564 - val_loss: 0.5234 - val_acc: 0.7386\n",
      "Epoch 2/5\n",
      "17964/17964 [==============================] - 765s 43ms/sample - loss: 0.5015 - acc: 0.7563 - val_loss: 0.4609 - val_acc: 0.7821\n",
      "Epoch 3/5\n",
      "17964/17964 [==============================] - 764s 43ms/sample - loss: 0.4438 - acc: 0.7951 - val_loss: 0.4342 - val_acc: 0.8037\n",
      "Epoch 4/5\n",
      "17964/17964 [==============================] - 767s 43ms/sample - loss: 0.4025 - acc: 0.8186 - val_loss: 0.4054 - val_acc: 0.8137\n",
      "Epoch 5/5\n",
      "17964/17964 [==============================] - 767s 43ms/sample - loss: 0.3730 - acc: 0.8327 - val_loss: 0.3744 - val_acc: 0.8328\n",
      "2-conv-64-nodes-1-dense-64--nodes-1561699755\n",
      "WARNING:tensorflow:From C:\\Users\\Nuxx\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 17964 samples, validate on 4492 samples\n",
      "Epoch 1/5\n",
      "17964/17964 [==============================] - 709s 39ms/sample - loss: 0.6170 - acc: 0.6538 - val_loss: 0.5101 - val_acc: 0.7487\n",
      "Epoch 2/5\n",
      "17964/17964 [==============================] - 736s 41ms/sample - loss: 0.5051 - acc: 0.7556 - val_loss: 0.4752 - val_acc: 0.7691\n",
      "Epoch 3/5\n",
      "17964/17964 [==============================] - 735s 41ms/sample - loss: 0.4507 - acc: 0.7874 - val_loss: 0.4431 - val_acc: 0.7905\n",
      "Epoch 4/5\n",
      "17964/17964 [==============================] - 723s 40ms/sample - loss: 0.3993 - acc: 0.8203 - val_loss: 0.4367 - val_acc: 0.8001\n",
      "Epoch 5/5\n",
      "17964/17964 [==============================] - 699s 39ms/sample - loss: 0.3477 - acc: 0.8457 - val_loss: 0.4565 - val_acc: 0.8023\n",
      "3-conv-64-nodes-1-dense-64--nodes-1561703364\n",
      "Train on 17964 samples, validate on 4492 samples\n",
      "Epoch 1/5\n",
      "17964/17964 [==============================] - 787s 44ms/sample - loss: 0.6242 - acc: 0.6429 - val_loss: 0.5880 - val_acc: 0.6859\n",
      "Epoch 2/5\n",
      "17964/17964 [==============================] - 747s 42ms/sample - loss: 0.5007 - acc: 0.7600 - val_loss: 0.4903 - val_acc: 0.7674\n",
      "Epoch 3/5\n",
      "17964/17964 [==============================] - 742s 41ms/sample - loss: 0.4293 - acc: 0.8029 - val_loss: 0.4169 - val_acc: 0.8063\n",
      "Epoch 4/5\n",
      "17964/17964 [==============================] - 780s 43ms/sample - loss: 0.3781 - acc: 0.8320 - val_loss: 0.4007 - val_acc: 0.8146\n",
      "Epoch 5/5\n",
      "17964/17964 [==============================] - 786s 44ms/sample - loss: 0.3320 - acc: 0.8532 - val_loss: 0.3930 - val_acc: 0.8192\n"
     ]
    }
   ],
   "source": [
    "conv_layers = [2, 3]\n",
    "dense_layers = [0, 1]\n",
    "layer_sizes = [64]\n",
    "\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = f\"{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{layer_size}--nodes-{int(time.time())}\"\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            print(NAME)\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            #Conv1 layer, input = image\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape = X_train.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            model.add(Flatten())\n",
    "                \n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(Dropout(0.2))\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation(\"sigmoid\"))\n",
    "            \n",
    "            \n",
    "            model.compile(loss=\"binary_crossentropy\",\n",
    "                            optimizer=\"adam\",\n",
    "                            metrics=['accuracy'])\n",
    "            \n",
    "            \n",
    "            model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# test_path = 'cats-and-dogs-full/test'\n",
    "\n",
    "\n",
    "# test_batches = ImageDataGenerator().flow_from_directory(test_path, \n",
    "#                                                         target_size=(70, 70),\n",
    "#                                                         color_mode=\"grayscale\",\n",
    "#                                                         classes=['dog','cat'],\n",
    "#                                                         shuffle=True,\n",
    "#                                                         batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_imgs, test_labels = next(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_labels = test_labels[:,0]\n",
    "# test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict_classes(test_batches, steps=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 70\n",
    "    img_array = cv2.imread(os.path.join(filepath), cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([prepare('cats-and-dogs-full/test/Cat/11000.jpg')])\n",
    "\n",
    "print(int(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORIES[int(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([prepare('cats-and-dogs-full/test/Dog/12000.jpg')])\n",
    "\n",
    "print(int(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORIES[int(predictions)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_cpu] *",
   "language": "python",
   "name": "conda-env-tensorflow_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
